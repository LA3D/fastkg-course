[
  {
    "objectID": "02_jsonld.html",
    "href": "02_jsonld.html",
    "title": "Working with JSON-LD",
    "section": "",
    "text": "We have been using the kglab tutorial to learn about using W3C web standards to construct knowledge graphs. One particularly useful standard that is briefly touched on in the tutorial is JSON-LD in the serialization exercise. This corresponds to building a knowledge graph with rdflib in the kglab/examples subdirectory. JSON-LD context\n\n\nThe beauty of JSON-LD lies in its ability to transform standard JSON data into a knowledge graph simply and efficiently. By adding a ‘(context?)’ to a JSON document, developers can define how the data should be interpreted semantically. This turns a flat data structure into an interconnected web of information, opening up powerful querying and linking possibilities.\n\n\n\nThe release of JSON-LD 1.1 introduced a range of new features aimed at enhancing its functionality and ease of use. Key updates include improved context management, support for graph containers, and the ability to nest node objects. These features make it easier to construct intricate knowledge graphs and offer more control over how data is contextualized."
  },
  {
    "objectID": "02_jsonld.html#some-notes-on-json-ld",
    "href": "02_jsonld.html#some-notes-on-json-ld",
    "title": "Working with JSON-LD",
    "section": "",
    "text": "We have been using the kglab tutorial to learn about using W3C web standards to construct knowledge graphs. One particularly useful standard that is briefly touched on in the tutorial is JSON-LD in the serialization exercise. This corresponds to building a knowledge graph with rdflib in the kglab/examples subdirectory. JSON-LD context\n\n\nThe beauty of JSON-LD lies in its ability to transform standard JSON data into a knowledge graph simply and efficiently. By adding a ‘(context?)’ to a JSON document, developers can define how the data should be interpreted semantically. This turns a flat data structure into an interconnected web of information, opening up powerful querying and linking possibilities.\n\n\n\nThe release of JSON-LD 1.1 introduced a range of new features aimed at enhancing its functionality and ease of use. Key updates include improved context management, support for graph containers, and the ability to nest node objects. These features make it easier to construct intricate knowledge graphs and offer more control over how data is contextualized."
  },
  {
    "objectID": "02_jsonld.html#json-ld-and-web-apis",
    "href": "02_jsonld.html#json-ld-and-web-apis",
    "title": "Working with JSON-LD",
    "section": "JSON-LD and Web APIs",
    "text": "JSON-LD and Web APIs\nIn the modern web ecosystem, APIs serve as the bridges between different services and applications. JSON-LD’s compatibility with web APIs makes it a top choice for developers needing to consume or provide structured, linked data. Its seamless integration with RESTful services ensures that you can work within a familiar environment while benefiting from enhanced data semantics.\nMoreover, JSON-LD’s ability to express linked data allows for more advanced operations such as data aggregation, filtering, and transformation directly via API calls. This creates opportunities for developing richer, more interactive applications that can adapt in real-time to changes in underlying data. For example, by utilizing JSON-LD in a RESTful API for a content management system, you could dynamically link related articles, authors, and tags, thereby providing a more enriched user experience.\nAdditionally, JSON-LD’s interoperability means it can be easily coupled with other web standards like OAuth for secure authentication or CORS for cross-origin resource sharing. This makes it not just a data format, but a comprehensive solution for building robust and scalable API ecosystems.\nFinally, JSON-LD also plays a significant role in the realm of Web APIs for semantic search engines and linked data platforms. These APIs can consume JSON-LD to understand the contextual relationships between different pieces of information, thereby enabling more intelligent and nuanced search queries."
  },
  {
    "objectID": "02_jsonld.html#example-exposing-json-ld-context-via-http-link-header",
    "href": "02_jsonld.html#example-exposing-json-ld-context-via-http-link-header",
    "title": "Working with JSON-LD",
    "section": "Example: Exposing JSON-LD Context via HTTP Link Header",
    "text": "Example: Exposing JSON-LD Context via HTTP Link Header\nIn many real-world applications, the JSON-LD context can be exposed via an HTTP link header, similar to how Schema.org does it. This enables clients to discover the context automatically and understand how to interpret the linked data.\nSuppose you have a RESTful API for a blog platform, and you want to expose a JSON-LD context for articles. The HTTP response could include a link header pointing to the JSON-LD context:\nHTTP/1.1 200 OK\nContent-Type: application/json\nLink: &lt;https://yourapi.com/docs/jsonldcontext.json&gt;; rel=\"http://www.w3.org/ns/json-ld#context\"; type=\"application/ld+json\"\nWith this setup, clients consuming the API can follow the link to fetch the context and understand the semantics of the data. Here is a simplified example of what the jsonldcontext.json might look like:\n{\n  \"@context\": {\n    \"title\": \"http://schema.org/headline\",\n    \"author\": \"http://schema.org/author\",\n    \"datePublished\": \"http://schema.org/datePublished\",\n    \"content\": \"http://schema.org/text\"\n  }\n}\nBy using the link header to expose the JSON-LD context, you’re making it easier for clients to consume and understand your API’s data. This aligns well with JSON-LD 1.1 conventions and allows for greater interoperability and semantic richness."
  },
  {
    "objectID": "02_jsonld.html#example-using-json-ld-to-construct-a-knowledge-graph-from-wikipedia-tables",
    "href": "02_jsonld.html#example-using-json-ld-to-construct-a-knowledge-graph-from-wikipedia-tables",
    "title": "Working with JSON-LD",
    "section": "Example: Using JSON-LD to construct a Knowledge Graph from Wikipedia tables",
    "text": "Example: Using JSON-LD to construct a Knowledge Graph from Wikipedia tables\nWikipedia can provide a starting point for structuring and enriching knowledge graphs. For our Navy project, we will want to provide LLM Agents with context for factual information that may have changed since “pre-training” using Retrieval Augmented Generation. For our purposes, we want to augment our KG with broader contextual information that may be useful to agents for question and answering. One set of context, is the List of current ships of the United States Navy that contain a number of tables that could be useful to add to our knowledge graph. Wikidata does contain most of the ships but the entities are not always complete. For example, the Wikidata entity page for USS Abraham Lincoln shows a rather rich set of relations including events that correspond to ship naming ceremony, ship commissioning. However, ships like USS Carter Hall are very basic and don’t contain a lot of information we can extract. Looking at the History for List of current ships of the United States Navy tells us that the page is fairly active and Wikipedia contributors are keeping it more up to date than the Wikidata entries.\nLets’ do a little Exploratory Data Analysis using large language models similar to Getting Started With LLMs. We will use Beautiful Soup to retreive the Wikipedia page and find the “html tables” in the document.\n\n\nCode\nimport requests\nfrom bs4 import BeautifulSoup\n\nurl = \"https://en.wikipedia.org/wiki/List_of_current_ships_of_the_United_States_Navy\"\nresponse = requests.get(url)\nsoup = BeautifulSoup(response.text, 'html.parser')\ntable = soup.find_all(\"table\")[0]\n\n\nNow that we have the tables, lets create a pandas dataframe from the table and sanity check that the table is the same as what is in the first table.\n\n\nCode\nimport pandas as pd\n\ndf = pd.read_html(str(table))[0]\ndf\n\n\n/tmp/ipykernel_4540/553751003.py:3: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n  df = pd.read_html(str(table))[0]\n\n\n\n\n\n\n\n\n\n\nShip name\nHull number\nClass\nType\nCommission date\nHomeport[2]\nNote\n\n\n\n\n0\nUSS Abraham Lincoln\nCVN-72\nNimitz\nAircraft carrier\n11 November 1989\nSan Diego, CA\n[3]\n\n\n1\nUSS Alabama\nSSBN-731\nOhio\nBallistic missile submarine\n25 May 1985\nBangor, WA\n[4]\n\n\n2\nUSS Alaska\nSSBN-732\nOhio\nBallistic missile submarine\n25 January 1986\nKings Bay, GA\n[5]\n\n\n3\nUSS Albany\nSSN-753\nLos Angeles\nAttack submarine\n7 April 1990\nNorfolk, VA\n[6]\n\n\n4\nUSS Alexandria\nSSN-757\nLos Angeles\nAttack submarine\n29 June 1991\nSan Diego, CA\n[7] Scheduled to be decommissioned 2026[8]\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n234\nUSS William P. Lawrence\nDDG-110\nArleigh Burke\nDestroyer\n19 May 2011\nSan Diego, CA\n[242]\n\n\n235\nUSS Winston S. Churchill\nDDG-81\nArleigh Burke\nDestroyer\n10 March 2001\nNorfolk, VA\n[243]\n\n\n236\nUSS Wichita\nLCS-13\nFreedom\nLittoral combat ship\n12 January 2019\nMayport, FL\n[244] Proposed to be decommissioned 2023[17]\n\n\n237\nUSS Wyoming\nSSBN-742\nOhio\nBallistic missile submarine\n13 July 1996\nKings Bay, GA\n[245]\n\n\n238\nUSS Zumwalt\nDDG-1000\nZumwalt\nDestroyer\n15 October 2016\nSan Diego, CA\n[246]\n\n\n\n\n239 rows × 7 columns\n\nFigure 1: Dataframe from Wikipedia Commissioned ship table.\n\n\n\nSo, if we want to use the column names as the basis for eventually constructing a URI, we unfortunately need to make it web safe and remove spaces and other issues. The other question is “what does a row” represent? If we want to build a knowledge graph of all of the ships of the navy, we might want to consider a basic ontology to start with. The first table is “commissioned” ships and the idea of commisioned is a role relationship since it has a start time and a end time.\n\n\nCode\ncolumn_names = df.columns.tolist()\ncolumn_names\n\n\n['Ship name',\n 'Hull number',\n 'Class',\n 'Type',\n 'Commission date',\n 'Homeport[2]',\n 'Note']\n\n\n\n\n\nCode\nimport json\nimport uuid\n\nfrom pprint import pprint\n\n# Normalize column names in DataFrame\nnormalized_columns = {col: col.replace(\" \", \"_\").replace(\"[\", \"\").replace(\"]\", \"\") for col in column_names}\ndf.rename(columns=normalized_columns, inplace=True)\n\n# Let's change the date to be consistent with xsd:date\n# df['Commission_date'] = pd.to_datetime(df['Commission_date']).dt.strftime('%Y-%m-%d')\n\n# Convert DataFrame to JSON-formatted string\ndf_json_str = df.to_json(orient=\"records\", indent=4)\n\n# Convert JSON-formatted string to Python object\ndf_json = json.loads(df_json_str)\n\n# Pretty-print the first record\npprint(df_json[0])\n\n\n{'Class': 'Nimitz',\n 'Commission_date': '11 November 1989',\n 'Homeport2': 'San Diego, CA',\n 'Hull_number': 'CVN-72',\n 'Note': '[3]',\n 'Ship_name': 'USS\\xa0Abraham Lincoln',\n 'Type': 'Aircraft carrier'}\n\nFigure 2: ?(caption)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A “Fast” Introduction to Knowledge Graphs",
    "section": "",
    "text": "Welcome to FastKG-Course, an interactive course designed to make you proficient in Knowledge Graphs, Semantic Technologies, Ontology, and more. This project is affiliated with the Laboratory for Assured AI Applications Development in the Center for Research Computing at the University of Notre Dame.\n\n\n\n\nInteractive Jupyter Notebooks\nHands-on Tutorials\nUse of fast.ai and kglab libraries\n\n\n\n\n\n\n\n\n\n\n(Optional) Fork this repository\nOpen the project in GitHub Codespaces\nThe devcontainer will automatically set up your environment\nStart the Jupyter server and open the introductory notebook\n\n\n\n\nBefore starting this course, it is highly recommended to complete the following Fast.ai courses:\n\nPractical Deep Learning for Coders\nDeep Learning for Coders with fastai & Pytorch\nJupyter Notebook 101\n\nAdditional requirements:\n\nBasic knowledge of Python\nFamiliarity with machine learning concepts\n\n\n\n\nNavigate through the Jupyter notebooks in sequence for a curated educational path, or feel free to explore topics that interest you.\nThe dev container is fully configured with software and KG and machine learning libraries needed for this course.\n\n\n\n\nCharles F Vardeman II\n\n\n\n\nThis project is part of the Laboratory for Assured AI Applications Development in the Center for Research Computing at the University of Notre Dame. The kglab project for providing some integrated tools for working with Knowledge Graphs as well as an excellent tutorial. Content generation and assistance have been facilitated using OpenAI’s GPT-4 language model. ChatGPT August 3, 2023 version\n\n\n\nThis project is dual-licensed under:\n\nMIT License for the software components. See LICENSE-MIT for more details.\nCreative Commons Attribution 4.0 International (CC BY 4.0) for the educational content. See LICENSE-CC-BY for more details.\nThe kglab submodule from derwen.ai is licensed under the MIT License.\n\nYou are free to use the project under either of the licenses, depending on your needs."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "A “Fast” Introduction to Knowledge Graphs",
    "section": "",
    "text": "Welcome to FastKG-Course, an interactive course designed to make you proficient in Knowledge Graphs, Semantic Technologies, Ontology, and more. This project is affiliated with the Laboratory for Assured AI Applications Development in the Center for Research Computing at the University of Notre Dame."
  },
  {
    "objectID": "index.html#features",
    "href": "index.html#features",
    "title": "A “Fast” Introduction to Knowledge Graphs",
    "section": "",
    "text": "Interactive Jupyter Notebooks\nHands-on Tutorials\nUse of fast.ai and kglab libraries"
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "A “Fast” Introduction to Knowledge Graphs",
    "section": "",
    "text": "(Optional) Fork this repository\nOpen the project in GitHub Codespaces\nThe devcontainer will automatically set up your environment\nStart the Jupyter server and open the introductory notebook"
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "A “Fast” Introduction to Knowledge Graphs",
    "section": "",
    "text": "Before starting this course, it is highly recommended to complete the following Fast.ai courses:\n\nPractical Deep Learning for Coders\nDeep Learning for Coders with fastai & Pytorch\nJupyter Notebook 101\n\nAdditional requirements:\n\nBasic knowledge of Python\nFamiliarity with machine learning concepts"
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "A “Fast” Introduction to Knowledge Graphs",
    "section": "",
    "text": "Navigate through the Jupyter notebooks in sequence for a curated educational path, or feel free to explore topics that interest you.\nThe dev container is fully configured with software and KG and machine learning libraries needed for this course."
  },
  {
    "objectID": "index.html#contributors",
    "href": "index.html#contributors",
    "title": "A “Fast” Introduction to Knowledge Graphs",
    "section": "",
    "text": "Charles F Vardeman II"
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "A “Fast” Introduction to Knowledge Graphs",
    "section": "",
    "text": "This project is part of the Laboratory for Assured AI Applications Development in the Center for Research Computing at the University of Notre Dame. The kglab project for providing some integrated tools for working with Knowledge Graphs as well as an excellent tutorial. Content generation and assistance have been facilitated using OpenAI’s GPT-4 language model. ChatGPT August 3, 2023 version"
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "A “Fast” Introduction to Knowledge Graphs",
    "section": "",
    "text": "This project is dual-licensed under:\n\nMIT License for the software components. See LICENSE-MIT for more details.\nCreative Commons Attribution 4.0 International (CC BY 4.0) for the educational content. See LICENSE-CC-BY for more details.\nThe kglab submodule from derwen.ai is licensed under the MIT License.\n\nYou are free to use the project under either of the licenses, depending on your needs."
  },
  {
    "objectID": "01_intro.html",
    "href": "01_intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Code\n# Import libraries\nimport fastai\nimport kglab\nimport pandas\n\n# Print versions\nprint(f'fastai version: {fastai.__version__}')\nprint(f'kglab version: {kglab.__version__}')\nprint(f'pandas version: {pandas.__version__}')\n\n\nfastai version: 2.7.12\nkglab version: 0.6.6\npandas version: 2.1.0\n\n\n\n\n\n\n                                                \nFigure 1: Timeline of Semantic Web Technologies"
  },
  {
    "objectID": "01_intro.html#introduction-to-knowledge-graphs-and-semantic-technologies",
    "href": "01_intro.html#introduction-to-knowledge-graphs-and-semantic-technologies",
    "title": "Introduction",
    "section": "",
    "text": "Code\n# Import libraries\nimport fastai\nimport kglab\nimport pandas\n\n# Print versions\nprint(f'fastai version: {fastai.__version__}')\nprint(f'kglab version: {kglab.__version__}')\nprint(f'pandas version: {pandas.__version__}')\n\n\nfastai version: 2.7.12\nkglab version: 0.6.6\npandas version: 2.1.0\n\n\n\n\n\n\n                                                \nFigure 1: Timeline of Semantic Web Technologies"
  }
]